---
title: "Intro to Regularized Logistic Regression using Citrus Classification"
date: 2022-10-07
draft: true
tags: [
    'Machine Learning',
    'Supervised Learning',
    'Logistic Regression',
    'Classification',
    'Python'
]
resources:
- name: "featured-image-preview"
  src: "pairplot.png"
---

# Introduction

In this post I'll be covering some of the intuition behind logistic regression, the sigmoid, and the logistic loss function through a binary classification exercise using a random citrus (orange/grapefruit) dataset I found on Kaggle.

# Why not MSE for Logistic Regression?

# The Humble Sigmoid & Logistic Loss
- talk about linear model for logistic regression
- sigmoid squishification function
- cost function for logistic regression

# Regularization
- what is regularization?
- the regularization term
- cost function for regularized logistic regression
- gradient descent for regularized logistic regression

# Minor Data Exploration
- graphs

# Python Implementation
## Label Encoding & Feature Scaling
- different types of feature scaling
- why do we do feature scaling
- StandardScaler() uses z-score normalization

## Fitting the model

## Evaluating the model

# References